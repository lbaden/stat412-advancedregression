---
  output: 
  html_document: 
  highlight: pygments
---


  
### Music Genre
  This data set was published as a contest data set on the TunedIT web site (http://tunedit.org/challenge/music-retrieval/genres). In this competition, the objective was to develop a predictive model for classifying music into six categories. In total, there were 12,495 music samples for which 191 characteristics were determined. All predictors were continuous; many were highly correlated and the predictors spanned different scales of measurement. This data collection was created using 60 performers from which 15–20 pieces of music were selected for each performer. Then 20 segments of each piece were parameterized in order to create the final data set. Hence, the samples are inherently not independent of each other.

```{r, eval = FALSE}
library(readr)
genres <- read_csv("https://raw.githubusercontent.com/natelangholz/stat412-advancedregression/master/week-7/problem-set-3/genresTrain.csv")
```

### 1
**Random Forest**: Fit a random forest model using both CART trees and conditional inference trees to the music genre predictors. What are the differences in the models? Do you have any difficulty on the full data set? 

Use the cforest function in the party package to fit a random forest model using conditional inference trees. The party package function varimp can calculate predictor importance. 

### 2
**Data Splitting**: What data splitting method(s) would you use for these data? Explain.

### 3
**Variable Importance**: Create a variable importance plot from you best model. What features are most important?

  * * *
  
### Simulated data
Friedman introduced several benchmark data sets create by simulation. One of these simulations used the following nonlinear equation to create data:

$$y = 10\sin(πx_1x_2)+20(x_3 −0.5)^2 +10x_4 +5x_5 +N(0,σ^2)$$
where the x values are random variables uniformly distributed between [0, 1] (there are also 5 other non-informative variables also created in the simulation). The package mlbench contains a function called `mlbench.friedman1` that simulates these data
```{r rf}
library(mlbench)
set.seed(200)
simulated <- mlbench.friedman1(200, sd = 1)
simulated <- cbind(simulated$x, simulated$y)
simulated <- as.data.frame(simulated)
colnames(simulated)[ncol(simulated)] <- "y"
```
  
### 4
**Random Forest and Variable Importance**:  Fit a random forest model to all of the predictors, then estimate the variable importance scores. Did the random forest model significantly use the uninformative predictors (V6 – V10)?

### 5
**Correlated Predictor**:Now add an additional predictor that is highly correlated with one of the informative predictors. For example:

```{r cor}
simulated$duplicate1 <- simulated$V1 + rnorm(200) * .1
cor(simulated$duplicate1, simulated$V1)
```

Fit another random forest model to these data. Did the importance score for V1 change? What happens when you add another predictor that is also highly correlated with V1?

### 6
**Gradient Boosted Machine**: Repeat the process in 5 and 6 with different tree models, such as boosted trees. Does the same pattern occur? 
  
  
### Pulling Punches Part 2

The two `.Rdata` files under week 7 come as an abbreviated version of punch profiles from a boxing system to measure acceleration of boxers during live fights. The `gridded` list from the second file below has each individual punch profile which has a list item being a 3 column data frame of time (in ms around the middle of the punch event), acceleration in x (forward-back in g's), and acceleration in y (side-to-side in g's). Also attached are some other fields which are of less importance and contribute to this being a somewhat messy data set.

```{r two, eval = FALSE}
#load(file = 'week-7/problem-set-3/boxer_features_and_force.Rdata')
#load(file = 'week-7/problem-set-3/force_punch_profiles.Rdata')
```

There are 1000 punch profiles each with an associated force (in Newtons) and boxer who threw the punch. Use the `ff` data frame as ground truth for punch force (variable =`force`) in addition to the rest of the boxer information. Other boxer information included variables around their size to be a proxy for 'effective mass'.

### 7
**Estimations**: Use features (and/or new features) created from your problem set 2 to estimate punch force using a MARS model. Use RMSE as your error estimate

### 8
**Estimations improved** Now try a few different (gbm, randomForest) models through the `caret` package and different data splitting techniques to compare. Comparing RMSE which model performs the best?






